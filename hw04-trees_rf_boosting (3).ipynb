{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение (ДВФУ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 4 (10 баллов)\n",
    "\n",
    "### Дедлайн: 4 апреля, 23:59\n",
    "\n",
    "Домашнее задание состоит из трёх частей. Каждое задание в каждой части оценивается в 1 балл, кроме единственного задания третьей части – оно оценивается в 1 балл + 1 бонусный балл (то есть максимально за домашнее задание можно получить 11 баллов; баллы выше 10 так и пойдут в формулы оценок). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Везде, где встречаются массивы или матрицы, подразумевается, что это `numpy.array`.\n",
    "\n",
    "2. Гуглите как можно больше! Если у вас появляется какой-то вопрос про использование метода numpy, скорее всего, на него уже есть ответ в Google – главное, правильно задать вопрос! Использование поисковика резко поощряется. \n",
    "\n",
    "3. Плагиат не допускается (нельзя просто так списать у друга). **НО:** можно использовать **любую** информацию из открытых Интернет-источников с указанием ссылки на них. Правила оформления из ДЗ 1 сохраняются.\n",
    "\n",
    "4. Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Основы построения решающие дерева (3 балла)\n",
    "\n",
    "В этой части все расчёты необходимо реализовывать в виде запрограммированных формул, например, на `numpy`. **Нельзя использовать готовые реализации**. Например, если в задании требуется рассчитать энтропию, то требуется в каком-то виде релизовать расчёт по формуле, но нельзя использовать готовую реализацию `some_module.entropy()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1:** Пусть известно, что в вершину решающего дерева попали 10 объектов, 8 из которых имеют метку класса $k_1$, а 2 – метку $k_2$. Посчитайте энтропию такого распределения классов (с натуральным логарифмом). Ответ округлите до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Энтропия =  0.5\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "K = 10\n",
    "k1 = 8\n",
    "k2 = 2\n",
    "p1 = k1/K\n",
    "p2 = k2/K\n",
    "H = -(p1 * np.log(p1) + p2 * np.log(p2)).round(2)\n",
    "\n",
    "print('Энтропия = ', H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2:** Пусть дополнительно известно, что вершина из предыдущего задания не является листовой и возможно такое разбиение, что в левое поддерево попадут все объекты класса $k_1$, а в правое - класса $k_2$. Посчитайте критерий информативности:\n",
    "\n",
    "$$\n",
    "Q(R_m, j, t) = H(R_m) - \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) - \\frac{|R_r|}{|R_m|}H(R_r),\n",
    "$$\n",
    "\n",
    "где $R_m$ - множество объектов в разбиваемой вершине, $j$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения, $R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n",
    "\n",
    "Теперь в качестве $H(R)$ будем использовать индекс Джини:\n",
    "\n",
    "$$\n",
    "H(R) = \\sum_k p_k(1-p_k)\n",
    "$$\n",
    "\n",
    " Ответ округлите до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Критерий информативности =  0.32\n"
     ]
    }
   ],
   "source": [
    "p1 = k1/K\n",
    "p2 = k2/K\n",
    "Hm = (p1 * (1 - p1) + p2 * (1 - p2))\n",
    "Hl = 0 #поскольку в левое поддерево попадают все объекты одного класса, а в правое - другого.\n",
    "Hr = 0\n",
    "\n",
    "Q = Hm - np.abs(k1/K)*Hl - np.abs(k2/K)*Hr\n",
    "Q = Q.round(2)\n",
    "print('Критерий информативности = ', Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3:** Пусть при построении дерева образовалась листовая вершина с 10 объектами, значения целевой переменной для которых следующие: [1, 10, 5, 18, 100, 30, 50, 61, 84, 47] (решается задача регрессии). Чему будут равны предсказания модели для этих объектов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Для модели регрессии каждому листу ставится в соответствие ответ - среднее значение, медиана или иная функция, в зависимости от функционала качества.\n",
    "Y = [1, 10, 5, 18, 100, 30, 50, 61, 84, 47]\n",
    "predict = np.average(Y)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Дереьвя, бэггинг и случайный лес (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной части будем работать [с задачей предсказания диабета у пациента](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data). Посмотрим на работу бэггинга над решающими деревьями и случайного леса, сравним их работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQk0lEQVR4nO3df6zd9V3H8edr7cYmnVBku2kKs9VUXRkyxxWJU3MrRjpcLCYj6cStW0gaI5qZzGRlf7gY08j+wBhBMpuxUAPupmGbrZvMNJ1XNBtjVBmlMKQO7DpIm/FrXiSYsrd/3C/mrr2Xe3rvOedyP/f5SJrz/X6+n+/5vN9t87pfvj3nS6oKSVJbXrfYBUiS+s9wl6QGGe6S1CDDXZIaZLhLUoNWLnYBAOeff36tW7du3ue/8MILnH322f0r6DVuufUL9rxc2POZOXjw4Peq6i0zHXtNhPu6deu4//77533+xMQEY2Nj/SvoNW659Qv2vFzY85lJ8l+zHfO2jCQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWpQT+Ge5Ikkh5I8kOT+buy8JPuTPNa9rp42/4YkR5I8muTKQRUvSZrZmVy5b6qqd1bVaLe/AzhQVRuAA90+STYCW4GLgM3ArUlW9LFmSdIcFnJbZguwu9veDVw9bXy8ql6qqseBI8BlC1hHknSG0sv/rCPJ48CzQAF/XVW7kjxXVedOm/NsVa1Ocgtwb1Xd0Y3fBtxdVXed8p7bge0AIyMjl46Pj8+7iRPPPM/xF+d9+rxdvPac4S8KTE5OsmrVqkVZe7HY8/Jgz2dm06ZNB6fdTfkhvT5+4N1V9WSStwL7k3zrVeZmhrHTfoJU1S5gF8Do6Ggt5CvHN9+5l5sODf9JCk9cOzb0NcGvaC8X9rw8DKrnnm7LVNWT3esJ4AtM3WY5nmQNQPd6opt+DLhw2ukXAE/2q2BJ0tzmDPckZyd58yvbwK8DDwH7gG3dtG3A3m57H7A1yVlJ1gMbgPv6XbgkaXa93MsYAb6Q5JX5f1tVX07yDWBPkuuAo8A1AFV1OMke4GHgJHB9Vb08kOolSTOaM9yr6tvAJTOMPw1cMcs5O4GdC65OkjQvfkNVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KCewz3JiiT/nuSL3f55SfYneax7XT1t7g1JjiR5NMmVgyhckjS7M7ly/wjwyLT9HcCBqtoAHOj2SbIR2ApcBGwGbk2yoj/lSpJ60VO4J7kA+A3g09OGtwC7u+3dwNXTxser6qWqehw4AlzWl2olST1JVc09KbkL+DPgzcAfVdV7kzxXVedOm/NsVa1Ocgtwb1Xd0Y3fBtxdVXed8p7bge0AIyMjl46Pj8+7iRPPPM/xF+d9+rxdvPac4S8KTE5OsmrVqkVZe7HY8/Jgz2dm06ZNB6tqdKZjK+c6Ocl7gRNVdTDJWA/rZYax036CVNUuYBfA6OhojY318tYzu/nOvdx0aM5W+u6Ja8eGvibAxMQEC/n9WorseXmw5/7pJRHfDfxmkquANwI/muQO4HiSNVX1VJI1wIlu/jHgwmnnXwA82c+iJUmvbs577lV1Q1VdUFXrmPqH0q9U1e8A+4Bt3bRtwN5uex+wNclZSdYDG4D7+l65JGlWC7mXcSOwJ8l1wFHgGoCqOpxkD/AwcBK4vqpeXnClkqSenVG4V9UEMNFtPw1cMcu8ncDOBdYmSZonv6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatCc4Z7kjUnuS/LNJIeT/Ek3fl6S/Uke615XTzvnhiRHkjya5MpBNiBJOl0vV+4vAb9aVZcA7wQ2J7kc2AEcqKoNwIFunyQbga3ARcBm4NYkKwZQuyRpFnOGe02Z7HZf3/0qYAuwuxvfDVzdbW8Bxqvqpap6HDgCXNbPoiVJr66ne+5JViR5ADgB7K+qrwMjVfUUQPf61m76WuA7004/1o1JkoZkZS+Tqupl4J1JzgW+kOQdrzI9M73FaZOS7cB2gJGRESYmJnopZUYjb4KPXnxy3ufP10JqXojJyclFW3ux2PPyYM/901O4v6KqnksywdS99ONJ1lTVU0nWMHVVD1NX6hdOO+0C4MkZ3msXsAtgdHS0xsbGzrz6zs137uWmQ2fUSl88ce3Y0NeEqR8qC/n9WorseXmw5/7p5dMyb+mu2EnyJuDXgG8B+4Bt3bRtwN5uex+wNclZSdYDG4D7+ly3JOlV9HK5uwbY3X3i5XXAnqr6YpKvAXuSXAccBa4BqKrDSfYADwMngeu72zqSpCGZM9yr6kHg52YYfxq4YpZzdgI7F1ydJGle/IaqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUHDfyCLJL3GrNvxpUVb+/bNZw/kfb1yl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWjOcE9yYZJ/SvJIksNJPtKNn5dkf5LHutfV0865IcmRJI8muXKQDUiSTtfLlftJ4KNV9XbgcuD6JBuBHcCBqtoAHOj26Y5tBS4CNgO3JlkxiOIlSTObM9yr6qmq+rdu+7+BR4C1wBZgdzdtN3B1t70FGK+ql6rqceAIcFmf65YkvYpUVe+Tk3XAPcA7gKNVde60Y89W1eoktwD3VtUd3fhtwN1Vddcp77Ud2A4wMjJy6fj4+LybOPHM8xx/cd6nz9vFa88Z/qLA5OQkq1atWpS1F4s9Lw+L1fOh7z4/9DVfsf6cFfPuedOmTQeranSmYyt7fZMkq4DPAX9YVd9PMuvUGcZO+wlSVbuAXQCjo6M1NjbWaymnufnOvdx0qOdW+uaJa8eGvibAxMQEC/n9WorseXlYrJ4/tONLQ1/zFbdvPnsgPff0aZkkr2cq2O+sqs93w8eTrOmOrwFOdOPHgAunnX4B8GR/ypUk9aKXT8sEuA14pKr+fNqhfcC2bnsbsHfa+NYkZyVZD2wA7utfyZKkufRyL+PdwAeAQ0ke6MY+DtwI7ElyHXAUuAagqg4n2QM8zNQnba6vqpf7XbgkaXZzhntV/Ssz30cHuGKWc3YCOxdQlyRpAfyGqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBc4Z7ks8kOZHkoWlj5yXZn+Sx7nX1tGM3JDmS5NEkVw6qcEnS7Hq5cr8d2HzK2A7gQFVtAA50+yTZCGwFLurOuTXJir5VK0nqyZzhXlX3AM+cMrwF2N1t7waunjY+XlUvVdXjwBHgsv6UKknqVapq7knJOuCLVfWObv+5qjp32vFnq2p1kluAe6vqjm78NuDuqrprhvfcDmwHGBkZuXR8fHzeTZx45nmOvzjv0+ft4rXnDH9RYHJyklWrVi3K2ovFnpeHxer50HefH/qar1h/zop597xp06aDVTU607GVC6rqdJlhbMafHlW1C9gFMDo6WmNjY/Ne9OY793LToX63Mrcnrh0b+poAExMTLOT3aymy5+VhsXr+0I4vDX3NV9y++eyB9DzfT8scT7IGoHs90Y0fAy6cNu8C4Mn5lydJmo/5hvs+YFu3vQ3YO218a5KzkqwHNgD3LaxESdKZmvNeRpLPAmPA+UmOAZ8AbgT2JLkOOApcA1BVh5PsAR4GTgLXV9XLA6pdkjSLOcO9qt4/y6ErZpm/E9i5kKIkSQvjN1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBAwv3JJuTPJrkSJIdg1pHknS6gYR7khXAXwHvATYC70+ycRBrSZJON6gr98uAI1X17ar6X2Ac2DKgtSRJp1g5oPddC3xn2v4x4BemT0iyHdje7U4meXQB650PfG8B589LPjnsFf/fovS7yOx5eVh2PW/65IJ6/vHZDgwq3DPDWP3QTtUuYFdfFkvur6rRfrzXUrDc+gV7Xi7suX8GdVvmGHDhtP0LgCcHtJYk6RSDCvdvABuSrE/yBmArsG9Aa0mSTjGQ2zJVdTLJ7wP/CKwAPlNVhwexVqcvt3eWkOXWL9jzcmHPfZKqmnuWJGlJ8RuqktQgw12SGrRkwn2uxxlkyl92xx9M8q7FqLOfeuj52q7XB5N8Nckli1FnP/X62IokP5/k5STvG2Z9g9BLz0nGkjyQ5HCSfx52jf3Ww9/tc5L8fZJvdj1/eDHq7Jckn0lyIslDsxzvf35V1Wv+F1P/KPufwE8AbwC+CWw8Zc5VwN1Mfcb+cuDri133EHr+RWB1t/2e5dDztHlfAf4BeN9i1z2EP+dzgYeBt3X7b13suofQ88eBT3bbbwGeAd6w2LUvoOdfAd4FPDTL8b7n11K5cu/lcQZbgL+pKfcC5yZZM+xC+2jOnqvqq1X1bLd7L1PfJ1jKen1sxR8AnwNODLO4Aeml598GPl9VRwGqaqn33UvPBbw5SYBVTIX7yeGW2T9VdQ9TPcym7/m1VMJ9pscZrJ3HnKXkTPu5jqmf/EvZnD0nWQv8FvCpIdY1SL38Of8UsDrJRJKDST44tOoGo5eebwHeztSXHw8BH6mqHwynvEXR9/wa1OMH+m3Oxxn0OGcp6bmfJJuYCvdfGmhFg9dLz38BfKyqXp66qFvyeul5JXApcAXwJuBrSe6tqv8YdHED0kvPVwIPAL8K/CSwP8m/VNX3B1zbYul7fi2VcO/lcQatPfKgp36S/CzwaeA9VfX0kGoblF56HgXGu2A/H7gqycmq+ruhVNh/vf7d/l5VvQC8kOQe4BJgqYZ7Lz1/GLixpm5IH0nyOPAzwH3DKXHo+p5fS+W2TC+PM9gHfLD7V+fLgeer6qlhF9pHc/ac5G3A54EPLOGruOnm7Lmq1lfVuqpaB9wF/N4SDnbo7e/2XuCXk6xM8iNMPWH1kSHX2U+99HyUqf9SIckI8NPAt4da5XD1Pb+WxJV7zfI4gyS/2x3/FFOfnLgKOAL8D1M/+ZesHnv+Y+DHgFu7K9mTtYSfqNdjz03ppeeqeiTJl4EHgR8An66qGT9StxT0+Of8p8DtSQ4xdcviY1W1ZB8FnOSzwBhwfpJjwCeA18Pg8svHD0hSg5bKbRlJ0hkw3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KD/g/dqvHa9wuV2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Outcome'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4:** Разделите данные на признаки и целевую переменную. Разбейте датасет на обучающую и тестовую части в отношении 7:3. Затем разделите обучающую выборку на обучающую-обучающую и обучающую-валидационную в соотношении 7:3 (то есть в итоге должно получиться три выборки: обучающая-обучающая (0.49 от исходного датасета), обучающая-валидационная (0.21 от исходного датасета) и тестовая (0.3 от исходного датасета)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Outcome']\n",
    "x = data.drop (\"Outcome\", axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "x_obuch, x_valid, y_obuch, y_valid = train_test_split(x_train, y_train, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((375, 8), (162, 8), (231, 8), (537, 8))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_obuch.shape, x_valid.shape, x_test.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5:** На обучающей-валидационной выборке подберите оптимальные значения гиперпараметров `max_depth` и `min_samples_leaf` для `DecisionTreeClassifier`. Для этого:\n",
    "1. Создайте списки с возможными значениями для перебора.\n",
    "2. Для каждой пары значений обучите дерево на обучающей-обучающей выборке и определите качество на обучающей-валидационной выборке. В качестве критерия будем использовать `f1-меру`.\n",
    "3. Выберите ту пару значений, которая даёт наилучшее качество на обучающей-валидационной выборке. \n",
    "\n",
    "\n",
    "Обучите решающее дерево с подобранными гиперпараметрами на **полной обучающей** выборке. Оцените качество классификации на тестовой выборке по метрикам `accuracy`, `precision` и `recall`, `auc_roc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 1\n",
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 2\n",
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 3\n",
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 4\n",
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 5\n",
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 6\n",
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 7\n",
      "f1:  0.5063291139240506 max_depth = 1 min_samples_leaf 8\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 1\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 2\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 3\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 4\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 5\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 6\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 7\n",
      "f1:  0.5063291139240506 max_depth = 2 min_samples_leaf 8\n",
      "f1:  0.4473684210526316 max_depth = 3 min_samples_leaf 1\n",
      "f1:  0.4473684210526316 max_depth = 3 min_samples_leaf 2\n",
      "f1:  0.5063291139240506 max_depth = 3 min_samples_leaf 3\n",
      "f1:  0.5063291139240506 max_depth = 3 min_samples_leaf 4\n",
      "f1:  0.5063291139240506 max_depth = 3 min_samples_leaf 5\n",
      "f1:  0.5063291139240506 max_depth = 3 min_samples_leaf 6\n",
      "f1:  0.5063291139240506 max_depth = 3 min_samples_leaf 7\n",
      "f1:  0.5063291139240506 max_depth = 3 min_samples_leaf 8\n",
      "f1:  0.5510204081632654 max_depth = 4 min_samples_leaf 1\n",
      "f1:  0.5510204081632654 max_depth = 4 min_samples_leaf 2\n",
      "f1:  0.6122448979591838 max_depth = 4 min_samples_leaf 3\n",
      "f1:  0.6122448979591838 max_depth = 4 min_samples_leaf 4\n",
      "f1:  0.6470588235294118 max_depth = 4 min_samples_leaf 5\n",
      "f1:  0.6601941747572816 max_depth = 4 min_samples_leaf 6\n",
      "f1:  0.6601941747572816 max_depth = 4 min_samples_leaf 7\n",
      "f1:  0.6601941747572816 max_depth = 4 min_samples_leaf 8\n",
      "f1:  0.6153846153846154 max_depth = 5 min_samples_leaf 1\n",
      "f1:  0.576923076923077 max_depth = 5 min_samples_leaf 2\n",
      "f1:  0.6530612244897959 max_depth = 5 min_samples_leaf 3\n",
      "f1:  0.6530612244897959 max_depth = 5 min_samples_leaf 4\n",
      "f1:  0.6666666666666667 max_depth = 5 min_samples_leaf 5\n",
      "f1:  0.6601941747572816 max_depth = 5 min_samples_leaf 6\n",
      "f1:  0.6601941747572816 max_depth = 5 min_samples_leaf 7\n",
      "f1:  0.6601941747572816 max_depth = 5 min_samples_leaf 8\n",
      "f1:  0.6000000000000001 max_depth = 6 min_samples_leaf 1\n",
      "f1:  0.5360824742268041 max_depth = 6 min_samples_leaf 2\n",
      "f1:  0.6236559139784946 max_depth = 6 min_samples_leaf 3\n",
      "f1:  0.6458333333333334 max_depth = 6 min_samples_leaf 4\n",
      "f1:  0.6597938144329897 max_depth = 6 min_samples_leaf 5\n",
      "f1:  0.6534653465346535 max_depth = 6 min_samples_leaf 6\n",
      "f1:  0.6534653465346535 max_depth = 6 min_samples_leaf 7\n",
      "f1:  0.6534653465346535 max_depth = 6 min_samples_leaf 8\n",
      "f1:  0.576271186440678 max_depth = 7 min_samples_leaf 1\n",
      "f1:  0.5378151260504201 max_depth = 7 min_samples_leaf 2\n",
      "f1:  0.5932203389830508 max_depth = 7 min_samples_leaf 3\n",
      "f1:  0.6153846153846153 max_depth = 7 min_samples_leaf 4\n",
      "f1:  0.638655462184874 max_depth = 7 min_samples_leaf 5\n",
      "f1:  0.6341463414634146 max_depth = 7 min_samples_leaf 6\n",
      "f1:  0.6168224299065421 max_depth = 7 min_samples_leaf 7\n",
      "f1:  0.6153846153846154 max_depth = 7 min_samples_leaf 8\n",
      "f1:  0.5306122448979591 max_depth = 8 min_samples_leaf 1\n",
      "f1:  0.48484848484848486 max_depth = 8 min_samples_leaf 2\n",
      "f1:  0.5384615384615384 max_depth = 8 min_samples_leaf 3\n",
      "f1:  0.6274509803921569 max_depth = 8 min_samples_leaf 4\n",
      "f1:  0.5825242718446602 max_depth = 8 min_samples_leaf 5\n",
      "f1:  0.5849056603773585 max_depth = 8 min_samples_leaf 6\n",
      "f1:  0.5862068965517241 max_depth = 8 min_samples_leaf 7\n",
      "f1:  0.5925925925925926 max_depth = 8 min_samples_leaf 8\n",
      "max f1 0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "maxdepth = range(1, 9)\n",
    "samplesleaf = range(1, 9)\n",
    "f1 = []                   \n",
    "\n",
    "for dep in maxdepth:\n",
    "    for leaf in samplesleaf:\n",
    "        dt = DecisionTreeClassifier (max_depth = dep, min_samples_leaf = leaf, random_state = 13)\n",
    "        dt.fit (x_obuch, y_obuch)\n",
    "        y_dt_pred = dt.predict(x_valid)\n",
    "        F1 = f1_score(y_valid, y_dt_pred)\n",
    "        print ('f1: ', F1, 'max_depth =', dep, 'min_samples_leaf', leaf)\n",
    "        f1.append(F1)\n",
    "print('max f1',np.max(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наибольшее качество показывает дерево, в котором max_depth = 5, min_samples_leaf = 5. F1 - мера в этом случае - 0.6667."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7489177489177489\n",
      "Precision = 0.7192982456140351\n",
      "Recall =  0.4939759036144578\n",
      "AUC_ROC =  0.8198062520351678\n"
     ]
    }
   ],
   "source": [
    "Tree =  DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 5,  random_state = 13)\n",
    "Tree.fit(x_train, y_train)\n",
    "y_tree_predict = Tree.predict(x_test)\n",
    "y_tree_roc = Tree.predict_proba(x_test)[:, 1]\n",
    "\n",
    "print ('Accuracy =', accuracy_score(y_test, y_tree_predict))\n",
    "print ('Precision =', precision_score(y_test, y_tree_predict))\n",
    "print ('Recall = ', recall_score(y_test, y_tree_predict))\n",
    "print ('AUC_ROC = ', roc_auc_score(y_test, y_tree_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6:** Обучите [`BaggingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) на 50 деревьях на **полной обучающей** выборке. Оцените качество классификации на тестовой выборке по тем же метрикам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7792207792207793\n",
      "Precision = 0.7285714285714285\n",
      "Recall = 0.6144578313253012\n",
      "AUC_ROC =  0.8390589384565289\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(n_estimators = 50, random_state = 13)\n",
    "bc.fit(x_train, y_train)\n",
    "y_bc_predict = bc.predict(x_test)\n",
    "y_bc_roc = bc.predict_proba(x_test)[:, 1]\n",
    "\n",
    "print('Accuracy =', accuracy_score (y_test, y_bc_predict))\n",
    "print('Precision =', precision_score (y_test, y_bc_predict))\n",
    "print('Recall =', recall_score (y_test, y_bc_predict))\n",
    "print('AUC_ROC = ', roc_auc_score (y_test, y_bc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7:** Выполните кросс-валидацию на полной обучающей выборке и подберите оптимальные значения гиперпараметров `max_depth` и `min_samples_split` для `Random Forest` с 50 деревьями. Для этого:\n",
    "\n",
    "1. Создайте списки с возможными значениями для перебора.\n",
    "2. Для каждой пары значений проведите кросс-валидацию на полной обучающей выборке. Количество разбиений выберите на ваш вкус. В качестве критерия будем использовать `f1-меру`. Усредните значение критерия по всем прогонам кросс-валидации. \n",
    "3. Выберите ту пару значений, которая даёт наилучшее среднее качество. \n",
    "\n",
    "Обучите случайный лес с подобранными гиперпараметрами на **полной обучающей** выборке. Оцените качество классификации по тем же метрикам. Какая из трёх построенных моделей показала себя лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.65924544 0.65924544 0.65924544 0.65924544 0.65924544\n",
      " 0.65924544 0.65924544        nan 0.74304865 0.74304865 0.74304865\n",
      " 0.74304865 0.74304865 0.74304865 0.74304865        nan 0.75981205\n",
      " 0.75981205 0.75794638 0.75794638 0.75794638 0.75794638 0.75608071\n",
      "        nan 0.7616639  0.76538143 0.77470978 0.77469596 0.77097844\n",
      " 0.76726092 0.77096462        nan 0.76915423 0.76916805 0.77845495\n",
      " 0.76914041 0.77097844 0.75981205 0.7747236         nan 0.78033444\n",
      " 0.76915423 0.75983969 0.77287175 0.75985351 0.76730238 0.7710199\n",
      "        nan 0.76914041 0.77657546 0.76915423 0.76912659 0.76916805\n",
      " 0.76728856 0.76914041        nan 0.75797402 0.76540907 0.77099226\n",
      " 0.78029298 0.77473742 0.77288557 0.77845495]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 6, 'min_samples_split': 2}, 0.7803344389165284)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://vc.ru/ml/147132-kak-avtomaticheski-podobrat-parametry-dlya-modeli-mashinnogo-obucheniya-ispolzuem-gridsearchcv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 13)\n",
    "rfc_list = {'max_depth': range(1, 9), 'min_samples_split': range(1, 9)}\n",
    "rfc_1 = GridSearchCV(rfc, rfc_list, cv = 4)\n",
    "rfc_1.fit(x_train, y_train)\n",
    "rfc_1.best_params_, rfc_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7835497835497836\n",
      "Precision = 0.7704918032786885\n",
      "Recall = 0.5662650602409639\n",
      "AUC_ROC = 0.8482578964506675\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 50, max_depth = 6, min_samples_split = 2, random_state= 13)\n",
    "rf.fit(x_train, y_train)\n",
    "y_rf_predict = rf.predict(x_test)\n",
    "y_rf_auc = rf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "print ('Accuracy =', accuracy_score(y_test, y_rf_predict))\n",
    "print ('Precision =', precision_score(y_test, y_rf_predict))\n",
    "print ('Recall =', recall_score(y_test, y_rf_predict))\n",
    "print ('AUC_ROC =', roc_auc_score(y_test, y_rf_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** в заданиях 5 и 7 приведены две популярные стратегии подбора гиперпараметров: (1) на отдельной валидационной выборке и (2) на кросс-валидации по обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8:** Постройте график зависимости AUC ROC на тестовой выборке от числа деревьев (`n_estimators`) для случайного леса, обучаемого на **полной обучающей** выборке. Какие выводы можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "n_estimators = range (1, 50)\n",
    "AUC_ROC = [] \n",
    "\n",
    "for n in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators = n, max_depth = 6, min_samples_split = 2, random_state= 13)\n",
    "    rf.fit(x_train, y_train)\n",
    "    rf_pr_roc = rf.predict_proba(x_test)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, rf_pr_roc)  \n",
    "    AUC_ROC.append(auc_roc)\n",
    "\n",
    "plt.plot(n_estimators, AUC_ROC)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('Зависимость AUC ROC от числа деревьев ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9:** Для лучшей модели случайного леса из задания 7 посчитайте важность признаков и постройте bar plot. Какой признак оказался самым важным для определения диабета? Приведите возможное объяснение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/08/xj6xy8m135v4rlv8c9ybmdpc0000gn/T/ipykernel_85793/2228291793.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mRf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Pregnancies'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Glucose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BloodPressure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SkinThickness'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Insulin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BMI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DPF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "Rf = RandomForestClassifier(n_estimators = 50, max_depth = 6, min_samples_split = 2, random_state = 13)\n",
    "Rf.fit(x_train, y_train)\n",
    "X = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI','DPF', 'Age']\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.bar(X, Rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Творческая часть (1 балл + 1 бонусный балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с задачей про задержки самолётов. На основании доступных данных о рейсе вам нужно определить, будет ли он задержан на 15 минут.\n",
    "Воспользуйтесь любыми методами градиентного бустинга (`XGboost`, `catboost`, `LightGBM`). 1 балл ставится за преодоление порога `roc_auc_score` **0.72** и ещё 1 бонусный балл за преодоление порога **0.74** на выборке `test` ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/PersDep/data-mining-intro-2021/main/hw08-boosting-clustering/flight_delays_train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/PersDep/data-mining-intro-2021/main/hw08-boosting-clustering/flight_delays_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "X_train = train[['Distance', 'DepTime']].values\n",
    "y_train = train['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\n",
    "X_test = test[['Distance', 'DepTime']].values\n",
    "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb_model.fit(X_train_part, y_train_part)\n",
    "roc_auc_score(y_valid, xgb_model.predict_proba(X_valid)[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
